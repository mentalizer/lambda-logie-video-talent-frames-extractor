import modal
import os
import shutil
import tempfile
import uuid
from datetime import datetime

# -----------------------------------------------------------------------------
# IMAGE SETUP: NVIDIA Devel + Build Tools (Clang/GCC)
# -----------------------------------------------------------------------------
image = (
    modal.Image.from_registry("nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04", add_python="3.11")
    .apt_install(
        "libgl1",
        "libglib2.0-0",
        "ffmpeg",
        "git",
        "wget",
        # NEW: Required compilers for building InsightFace from source
        "build-essential",
        "clang",
        "python3-dev"
    )
    # Pre-install build dependencies to ensure headers are available
    .pip_install("cython", "numpy==1.26.3", "setuptools", "wheel")
    .pip_install(
        "insightface==0.7.3",
        "onnxruntime-gpu==1.16.3",
        "opencv-python-headless==4.9.0.80",
        "boto3==1.34.0",
        "scikit-learn==1.4.0",
        "fastapi",
        "httpx",
        "webvtt-py==0.4.6",
        "requests",
        "m3u8",
        "ffmpeg-python",
    )
    # CLEANUP: Remove CPU onnxruntime forced by insightface
    .run_commands(
        "pip uninstall -y onnxruntime || true",
        "pip show onnxruntime-gpu",
        "echo 'Cleaned CPU libs'"
    )
)

app = modal.App("video-only-extractor", image=image)
model_cache = modal.Volume.from_name("insightface-models", create_if_missing=True)

# -----------------------------------------------------------------------------
# UNIFIED FUNCTION (GPU + WEB ENDPOINT)
# -----------------------------------------------------------------------------
@app.function(
    gpu="T4",
    timeout=900,
    secrets=[modal.Secret.from_name("aws-s3-credentials")],
    volumes={"/root/.insightface": model_cache},
    container_idle_timeout=120,
    allow_concurrent_inputs=1,
)
@modal.fastapi_endpoint(method="POST")
def process(request: dict) -> dict:
    """
    Unified Endpoint: Receives request AND processes video on the same T4 GPU.
    """
    import cv2
    import boto3
    import time
    import numpy as np
    import insightface
    import onnxruntime
    from sklearn.cluster import DBSCAN
    from sklearn.preprocessing import normalize
    import requests

    # 1. IMMEDIATE HARDWARE VERIFICATION
    print("\n" + "="*50)
    print("üîç DIAGNOSTIC: CHECKING HARDWARE...")

    if os.system("nvidia-smi") != 0:
        print("‚ùå CRITICAL: nvidia-smi failed. No GPU attached!")
    else:
        print("‚úÖ HARDWARE: NVIDIA GPU Detected")

    providers = onnxruntime.get_available_providers()
    print(f"üîç ONNX Providers: {providers}")

    if 'CUDAExecutionProvider' not in providers:
        print("‚ùå CRITICAL: ONNX Runtime is running on CPU! 'onnxruntime-gpu' is not linked.")
        raise RuntimeError("GPU Library Mismatch - CUDA Provider Missing")
    else:
        print("‚úÖ SOFTWARE: CUDA Execution Provider Available")
    print("="*50 + "\n")

    # 2. PARSE REQUEST
    metadata = request.get("metadata", {})
    video_url = request.get("video_url")

    if "amazon_data" in request:
        print("üì¶ Processing Amazon Payload...")
        amz = request["amazon_data"]
        metadata.update({"aci_content_id": amz.get("aci_content_id")})
        video_url = amz.get("hls_url")
        if not video_url and amz.get("video_preview_assets"):
            video_url = amz["video_preview_assets"][0].get("url")

    if not video_url:
        return {"error": "No video_url found in request"}

    # 3. PROCESSING LOGIC
    start_time = time.perf_counter()
    job_id = str(uuid.uuid4())
    date_folder = datetime.now().strftime("%Y-%m-%d")
    s3 = boto3.client('s3')
    bucket = "logie-users"

    temp_dir = tempfile.mkdtemp()
    try:  # All files go to logie-users bucket

    try:
        temp_dir = tempfile.mkdtemp()

        # 1. Download video (handle HLS streams for short videos)
        print(f"Downloading video from: {video_url}")

        # Download video - handle both MP4 and HLS URLs
        if video_url.endswith('.mp4'):
            print("üé¨ Downloading MP4 video...")
            video_response = requests.get(video_url, stream=True, timeout=60)  # Longer timeout for full videos
            video_response.raise_for_status()

            video_path = os.path.join(temp_dir, "video.mp4")
            with open(video_path, 'wb') as f:
                for chunk in video_response.iter_content(chunk_size=8192):
                    f.write(chunk)

            file_size = os.path.getsize(video_path)
            print(f"‚úÖ MP4 download succeeded: {file_size} bytes")

        elif video_url.endswith('.m3u8') or 'hls' in video_url.lower():
            print("üé¨ Detected HLS stream URL - using ffmpeg conversion...")

            # Use ffmpeg to convert HLS to MP4
            try:
                import ffmpeg
                video_path = os.path.join(temp_dir, "video.mp4")

                print(f"üé¨ Converting HLS to MP4 using ffmpeg: {video_url}")

                # Use ffmpeg-python to convert HLS to MP4
                stream = ffmpeg.input(video_url)
                stream = ffmpeg.output(stream, video_path,
                                      vcodec='copy',  # Copy video codec (no re-encoding)
                                      acodec='copy',  # Copy audio codec (no re-encoding)
                                      avoid_negative_ts='make_zero')

                # Run ffmpeg
                ffmpeg.run(stream, overwrite_output=True, quiet=False)

                # Verify output
                if os.path.exists(video_path) and os.path.getsize(video_path) > 0:
                    file_size = os.path.getsize(video_path)
                    print(f"‚úÖ HLS‚ÜíMP4 conversion successful: {file_size} bytes")
                else:
                    raise ValueError("FFmpeg conversion failed - output file not created or empty")

            except Exception as ffmpeg_error:
                print(f"‚ùå FFmpeg HLS conversion failed: {ffmpeg_error}")
                raise ValueError(f"HLS conversion failed: {str(ffmpeg_error)}\n\nThis usually means:\n- HLS stream is not accessible\n- FFmpeg is not properly installed\n- Video content is protected/restricted")

        else:
            # Unknown format - try direct download
            print(f"‚ö†Ô∏è Unknown video format, attempting direct download...")
            video_response = requests.get(video_url, stream=True, timeout=30)
            video_response.raise_for_status()

            video_path = os.path.join(temp_dir, "video.mp4")
            with open(video_path, 'wb') as f:
                for chunk in video_response.iter_content(chunk_size=8192):
                    f.write(chunk)

            file_size = os.path.getsize(video_path)
            print(f"‚úÖ Unknown format download succeeded: {file_size} bytes")

        print("Video download complete.")

        # 2. Download transcript if provided
        transcript_data = []
        if transcript_url:
            print(f"Downloading transcript from: {transcript_url}")
            transcript_response = requests.get(transcript_url)
            transcript_response.raise_for_status()

            import webvtt
            transcript_content = transcript_response.text

            with tempfile.NamedTemporaryFile(mode='w', suffix='.vtt', delete=False, encoding='utf-8') as tf:
                tf.write(transcript_content)
                vtt_path = tf.name

            for caption in webvtt.read(vtt_path):
                txt = caption.text.strip().replace('\n', ' ')
                speaker = None
                if ':' in txt:
                    parts = txt.split(':', 1)
                    if len(parts[0]) < 40:
                        speaker = parts[0].strip()
                        txt = parts[1].strip()
                transcript_data.append({
                    'start': caption.start_in_seconds,
                    'end': caption.end_in_seconds,
                    'speaker': speaker,
                    'text': txt
                })
            os.remove(vtt_path)
            print("Transcript download complete.")

        # 3. Get video metadata and validate
        print(f"Validating downloaded video file: {video_path}")

        # Check file exists and has content
        if not os.path.exists(video_path):
            raise ValueError(f"Downloaded video file does not exist: {video_path}")

        file_size = os.path.getsize(video_path)
        print(f"Downloaded file size: {file_size} bytes")

        if file_size == 0:
            raise ValueError(f"Downloaded video file is empty (0 bytes): {video_path}")

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"Cannot open video file with OpenCV: {video_path}")

        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0
        v_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        v_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        cap.release()

        print(f"Video metadata: {duration:.1f}s, {total_frames} frames, {fps:.1f} fps, {v_w}x{v_h}")

        # Validate video has content
        if duration == 0 or total_frames == 0:
            raise ValueError(f"Video appears to be empty or corrupted: duration={duration}s, frames={total_frames}, fps={fps}")

        if v_w == 0 or v_h == 0:
            raise ValueError(f"Video has invalid resolution: {v_w}x{v_h}")

        # Additional validation for short videos
        if duration < 1.0:
            print(f"‚ö†Ô∏è Warning: Video is very short ({duration:.1f}s). This might be a preview or corrupted file.")

        print("‚úÖ Video validation passed")

        # 4. Initialize face detection
        print("üöÄ Initializing face detection on NVIDIA T4 GPU...")

        try:
            # We explicitly REMOVE CPUExecutionProvider to force a crash if GPU fails
            face_app = insightface.app.FaceAnalysis(
                name='buffalo_l',
                providers=['CUDAExecutionProvider']
            )
            face_app.prepare(ctx_id=0, det_size=(320, 320))
            print("‚úÖ SUCCESS: InsightFace initialized on GPU (CUDA Mode).")
        except Exception as e:
            print(f"‚ùå FATAL ERROR: GPU init failed: {e}")
            raise RuntimeError(f"GPU Init Failed. Error: {e}")

        # 5. Scan video for faces
        stride_sec = 1.0 if duration < 600 else (2.0 if duration < 1800 else 5.0)
        stride_frames = max(1, int(fps * stride_sec))
        all_faces = []

        print(f"Scanning every {stride_sec}s...")
        cap = cv2.VideoCapture(video_path)
        processed_frames = 0

        # Performance monitoring
        inference_start = time.perf_counter()

        for f_idx in range(0, total_frames, stride_frames):
            cap.set(cv2.CAP_PROP_POS_FRAMES, f_idx)
            ret, frame = cap.read()
            if not ret: break

            faces = face_app.get(frame)
            for face in faces:
                if face.det_score < 0.6: continue
                box, yaw, pitch, roll = face.bbox, *face.pose
                area = (box[2] - box[0]) * (box[3] - box[1])
                size_ratio = area / (frame.shape[0] * frame.shape[1])
                pose_score = max(0, 100 - (abs(yaw) * 1.2 + abs(pitch) + abs(roll) / 2))
                q_score = (face.det_score * 40) + (pose_score * 0.4) + (size_ratio * 100 * 0.2)

                all_faces.append({
                    'embedding': face.embedding,
                    'score': q_score,
                    'frame_idx': f_idx,
                    'timestamp': f_idx / fps,
                    'bbox': box
                })

            processed_frames += 1
            if processed_frames % 50 == 0:
                elapsed = time.perf_counter() - inference_start
                fps_processing = processed_frames / elapsed
                print(f"Processed {processed_frames} frames ({fps_processing:.1f} FPS)...")

        cap.release()

        # Verify if we actually used the GPU by checking speed
        inference_time = time.perf_counter() - inference_start
        processing_fps = processed_frames / inference_time if inference_time > 0 else 0
        print(f"üèÅ Inference Complete: {processed_frames} frames in {inference_time:.2f}s ({processing_fps:.1f} FPS)")

        # 6. Process transcript context
        def get_context(ts):
            for e in transcript_data:
                if e['start'] <= ts <= e['end']: return e['speaker'], e['text']
            for e in transcript_data:
                if abs(e['start'] - ts) < 2.0: return e['speaker'], e['text']
            return None, None

        # 7. Generate representative frames
        rep_indices = set([0, min(29, total_frames-1), max(0, total_frames-31), max(0, total_frames-2)])
        if total_frames > 10:
            for p in np.linspace(30, total_frames-31, 10).astype(int)[1:-1]: rep_indices.add(int(p))
        while len(rep_indices) < 10 and len(rep_indices) < total_frames: rep_indices.add(len(rep_indices))
        sorted_rep = sorted(list(rep_indices))[:10]

        # 8. Upload results to job-based folder structure
        base_path = f"extracted-frames/{date_folder}/{job_id}"
        talent_results = []

        # Upload representative frames
        rep_results = []
        cap = cv2.VideoCapture(video_path)
        for i, f_idx in enumerate(sorted_rep):
            cap.set(cv2.CAP_PROP_POS_FRAMES, f_idx)
            ret, frame = cap.read()
            if not ret: continue

            frame_filename = f"representative_frame_{i}.jpg"
            s3_key = f"{base_path}/{frame_filename}"

            # Save and upload
            frame_path = os.path.join(temp_dir, frame_filename)
            cv2.imwrite(frame_path, cv2.resize(frame, (1920, 1080) if frame.shape[1] >= frame.shape[0] else (1080, 1920)))
            s3_client.upload_file(frame_path, bucket_name, s3_key, ExtraArgs={'ContentType': 'image/jpeg'})

            rep_results.append({
                "frame_index": int(f_idx),
                "filename": frame_filename,
                "s3_key": s3_key,
                "s3_url": f"https://{bucket_name}.s3.amazonaws.com/{s3_key}",
                "timestamp": round(f_idx / fps, 2)
            })
        cap.release()

        # Process and upload talent frames
        if all_faces:
            embeddings = normalize(np.array([f['embedding'] for f in all_faces]))
            labels = DBSCAN(eps=0.65, min_samples=3).fit(embeddings).labels_
            unique = {}

            for i, l in enumerate(labels):
                if l != -1 and (l not in unique or all_faces[i]['score'] > unique[l]['score']):
                    unique[l] = all_faces[i]

            for person_id, face_data in unique.items():
                speaker, context = get_context(face_data['timestamp'])

                # Re-extract frame
                cap = cv2.VideoCapture(video_path)
                cap.set(cv2.CAP_PROP_POS_FRAMES, face_data['frame_idx'])
                ret, frame = cap.read()
                cap.release()

                if ret:
                    frame_filename = f"person_{person_id}.jpg"
                    s3_key = f"{base_path}/{frame_filename}"

                    # Save and upload
                    frame_path = os.path.join(temp_dir, frame_filename)
                    cv2.imwrite(frame_path, cv2.resize(frame, (1920, 1080) if frame.shape[1] >= frame.shape[0] else (1080, 1920)))
                    s3_client.upload_file(frame_path, bucket_name, s3_key, ExtraArgs={'ContentType': 'image/jpeg'})

                    talent_results.append({
                        "person_id": int(person_id),
                        "filename": frame_filename,
                        "s3_key": s3_key,
                        "s3_url": f"https://{bucket_name}.s3.amazonaws.com/{s3_key}",
                        "name": speaker if speaker else f"Person {person_id}",
                        "context_text": context,
                        "timestamp": round(face_data['timestamp'], 2),
                        "score": round(float(face_data['score']), 2)
                    })

        # Upload the full video to our S3 bucket for archiving
        video_s3_key = None
        video_s3_url = None

        try:
            # Use content_id from metadata for filename, fallback to job_id
            content_id = metadata.get('aci_content_id') or metadata.get('content_id') or job_id
            video_filename = f"{content_id}.mp4"
            video_s3_key = f"amazon-shorts/{date_folder}/{video_filename}"

            print(f"Uploading full video to S3: {video_s3_key}")
            s3_client.upload_file(video_path, bucket_name, video_s3_key, ExtraArgs={
                'ContentType': 'video/mp4',
                'Metadata': {
                    'source_url': video_url,
                    'job_id': job_id,
                    'processed_at': datetime.now().isoformat(),
                    'duration_seconds': str(round(duration, 2)),
                    'resolution': f"{v_w}x{v_h}"
                }
            })
            video_s3_url = f"https://{bucket_name}.s3.amazonaws.com/{video_s3_key}"
            print(f"Video archived successfully: {video_s3_url}")

        except Exception as upload_error:
            print(f"Failed to upload video to S3: {upload_error}")
            # Continue processing even if upload fails

        # Calculate processing metrics
        proc_time = round(time.perf_counter() - start_perf, 2)
        gpu_cost = round(proc_time * 0.000416, 4)  # T4 GPU cost per second

        # Extract transcription text (limit to 1000 characters)
        transcription_text = ""
        if transcript_data:
            # Concatenate all text entries with timestamps
            text_parts = []
            for entry in transcript_data:
                if entry.get('text'):
                    timestamp = f"[{entry['start']:.1f}s] "
                    speaker = f"{entry.get('speaker')}: " if entry.get('speaker') else ""
                    text_parts.append(f"{timestamp}{speaker}{entry['text']}")

            transcription_text = " ".join(text_parts)
            # Limit to 1000 characters
            if len(transcription_text) > 1000:
                transcription_text = transcription_text[:997] + "..."

        result = {
            "status": "success",
            "job_id": job_id,
            "processing_metrics": {
                "duration_seconds": proc_time,
                "inference_fps": round(processing_fps, 1),
                "estimated_cost_usd": gpu_cost,
                "gpu_type": "NVIDIA T4"
            },
            "video_metadata": {
                "duration_seconds": round(duration, 2),
                "resolution": f"{v_w}x{v_h}",
                "archived_s3_url": video_s3_url
            },
            "transcription": transcription_text,
            "talent_frames": sorted(talent_results, key=lambda x: x['person_id']),
            "representative_frames": rep_results
        }

        # Send webhook
        try:
            import httpx
            httpx.post(
                "https://hook.us1.make.com/qb8jajua119emykshhxdkl7wrbrct4cr",
                json=result,
                timeout=10.0
            )
        except Exception as e:
            print(f"Webhook failed: {e}")

        return result

    except Exception as e:
        print(f"ERROR: {str(e)}")
        import traceback
        traceback.print_exc()
        raise e
    finally:
        if 'temp_dir' in locals() and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir, ignore_errors=True)


def download_hls_to_mp4(hls_url: str, temp_dir: str) -> str:
    """
    Download HLS stream and convert to MP4 for short videos (10-30 seconds).

    Args:
        hls_url: URL to the HLS .m3u8 playlist
        temp_dir: Temporary directory to store files

    Returns:
        Path to the converted MP4 file
    """
    import m3u8
    import urllib.parse

    output_path = os.path.join(temp_dir, "video.mp4")

    try:
        print(f"Starting HLS download from: {hls_url}")

        # Download and parse HLS playlist
        print("Downloading HLS playlist...")
        playlist_response = requests.get(hls_url, timeout=10)
        playlist_response.raise_for_status()
        print(f"Playlist downloaded, {len(playlist_response.text)} characters")

        # Parse the playlist
        print("Parsing HLS playlist...")
        playlist = m3u8.loads(playlist_response.text)

        if not playlist.segments:
            print("No segments found in playlist, checking if it's a variant playlist...")
            # Check if it's a variant playlist (multiple quality options)
            if playlist.playlists:
                print(f"Found {len(playlist.playlists)} quality variants")
                # Sort variants by bandwidth (higher bandwidth = better quality)
                sorted_variants = sorted(playlist.playlists,
                                       key=lambda v: v.stream_info.bandwidth if v.stream_info else 0,
                                       reverse=True)
                best_variant = sorted_variants[0]  # Highest quality
                print(f"Using highest quality variant (bandwidth: {best_variant.stream_info.bandwidth if best_variant.stream_info else 'unknown'})")

                # Get the media playlist URL for the best variant
                variant_url = urllib.parse.urljoin(hls_url, best_variant.uri)
                print(f"Downloading media playlist: {variant_url}")
                variant_response = requests.get(variant_url, timeout=10)
                variant_response.raise_for_status()
                playlist = m3u8.loads(variant_response.text)
                hls_url = variant_url  # Update base URL for segments
            else:
                raise ValueError("Playlist has no segments and no variants. This doesn't appear to be a valid HLS playlist.")

        if not playlist.segments:
            raise ValueError(f"No segments found even after checking variants. Original content: {playlist_response.text[:500]}")

        print(f"Found {len(playlist.segments)} HLS segments to download")

        # Download all segments
        segment_files = []
        base_url = urllib.parse.urljoin(hls_url, '.')

        for i, segment in enumerate(playlist.segments):
            segment_url = urllib.parse.urljoin(base_url, segment.uri)
            segment_path = os.path.join(temp_dir, f"segment_{i:03d}.ts")

            try:
                # Download segment
                segment_response = requests.get(segment_url, timeout=15)
                segment_response.raise_for_status()

                with open(segment_path, 'wb') as f:
                    f.write(segment_response.content)

                segment_files.append(segment_path)
                print(f"Downloaded segment {i+1}/{len(playlist.segments)} ({len(segment_response.content)} bytes)")

            except Exception as seg_e:
                print(f"Failed to download segment {i+1}: {segment_url} - {seg_e}")
                # Continue with other segments if possible
                continue

        if not segment_files:
            raise ValueError("Failed to download any HLS segments")

        # Concatenate all segments into MP4
        print(f"Concatenating {len(segment_files)} segments into MP4...")
        with open(output_path, 'wb') as outfile:
            for segment_file in segment_files:
                with open(segment_file, 'rb') as infile:
                    outfile.write(infile.read())

        # Verify the output file
        if os.path.getsize(output_path) == 0:
            raise ValueError("Created MP4 file is empty")

        print(f"Successfully created MP4 ({os.path.getsize(output_path)} bytes) from {len(segment_files)} HLS segments")

        # Clean up segment files
        for segment_file in segment_files:
            try:
                os.remove(segment_file)
            except OSError:
                pass

        return output_path

    except Exception as e:
        print(f"‚ùå HLS download failed: {e}")
        import traceback
        traceback.print_exc()

        # Provide more specific error messages
        if "No segments found" in str(e):
            error_msg = "HLS playlist contains no video segments. This might be a master playlist that needs further processing, or the stream might be unavailable."
        elif "Failed to download" in str(e):
            error_msg = "Failed to download HLS segments. The video stream might be protected, expired, or require authentication."
        elif "variant" in str(e).lower():
            error_msg = "Failed to process HLS variant playlist. The stream structure might be different than expected."
        else:
            error_msg = f"HLS processing failed: {str(e)}"

        raise ValueError(f"HLS Video Download Failed: {error_msg}")


@app.function()
@modal.fastapi_endpoint(method="POST")
def process_video_job(request: dict) -> dict:
    """
    Simplified API endpoint for video-only processing.

    Supports multiple payload formats:

    1. Direct URLs:
    {
        "video_url": "https://example.com/video.mp4",
        "transcript_url": "https://example.com/transcript.vtt",
        "metadata": {"job_name": "My Video"}
    }

    2. Amazon Live data:
    {
        "amazon_data": {
            "broadcast_id": "02c4ee7e633246e384019e387bbf6db4",
            "hls_url": "https://m.media-amazon.com/images/S/vse-vms-transcoding-artifact-us-east-1-prod/...",
            "closed_captions": "en,https://m.media-amazon.com/images/S/vse-vms-closed-captions-artifact-us-east-1-prod/...",
            "video_preview_assets": [{"url": "https://...", "type": "default"}],
            ...
        },
        "metadata": {"shop_id": "influencer-7feb78c5", "broadcast_title": "..."}
    }
    """
    import requests

    print("üé¨ Starting video processing job...")
    print(f"Request keys: {list(request.keys())}")

    metadata = request.get("metadata", {})

    # Handle Amazon Live data format
    if "amazon_data" in request:
        print("üìä Processing Amazon Live data format")
        amazon_data = request["amazon_data"]

        # Extract video URL - prioritize HLS for short videos (10-30 seconds)
        video_url = None

        # For Amazon Live videos, prioritize HLS URLs since they contain the actual video content
        video_url = None

        # Primary: Use HLS URL directly (will be converted to MP4 by ffmpeg)
        if "hls_url" in amazon_data and amazon_data["hls_url"]:
            video_url = amazon_data["hls_url"]
            print(f"üé• Using HLS stream for full video content: {video_url}")

        # Fallback: MP4 previews (short clips only)
        if not video_url:
            if "video_preview_assets" in amazon_data and amazon_data["video_preview_assets"]:
                print("‚ö†Ô∏è No HLS URL found, using MP4 preview (short clip)")
                mp4_assets = [asset for asset in amazon_data["video_preview_assets"]
                             if asset.get("mimeType") == "video/mp4"]

                if mp4_assets:
                    # Sort by URL length (proxy for quality/file size)
                    mp4_assets.sort(key=lambda x: len(x.get("url", "")), reverse=True)
                    video_url = mp4_assets[0]["url"]
                    print(f"Selected largest MP4 preview: {video_url}")
                else:
                    # If no MP4 previews, try any video format
                    all_assets = amazon_data["video_preview_assets"]
                    if all_assets:
                        all_assets.sort(key=lambda x: len(x.get("url", "")), reverse=True)
                        video_url = all_assets[0]["url"]
                        print(f"Selected largest available preview: {video_url}")

        # Last resort: Try constructed MP4 URLs (unlikely to work for Amazon Live)
        if not video_url:
            broadcast_id = amazon_data.get("broadcast_id")
            if broadcast_id:
                mp4_url = f"https://m.media-amazon.com/images/S/vse-vms-transcoding-artifact-us-east-1-prod/{broadcast_id}/default.jobtemplate.mp4"
                print(f"üö® ABSOLUTE LAST RESORT: Trying constructed MP4 URL: {mp4_url}")
                video_url = mp4_url

        # Extract transcript URL from closed_captions
        transcript_url = None
        if "closed_captions" in amazon_data and amazon_data["closed_captions"]:
            # Format: "en,https://url.vtt" or just "https://url.vtt"
            captions = amazon_data["closed_captions"]
            if "," in captions:
                parts = captions.split(",", 1)
                transcript_url = parts[1] if len(parts) > 1 else parts[0]
            else:
                transcript_url = captions

        # Merge Amazon metadata
        if amazon_data:
            metadata.update({
                "broadcast_id": amazon_data.get("broadcast_id"),
                "shop_id": amazon_data.get("shop_id"),
                "broadcast_title": amazon_data.get("broadcast_title"),
                "aci_content_id": amazon_data.get("aci_content_id"),
                "reference_id": amazon_data.get("reference_id"),
                "synopsis": amazon_data.get("synopsis"),
                "formatted_duration": amazon_data.get("formatted_duration"),
            })

    else:
        print("üîó Processing direct URL format")
        # Direct URL format
        video_url = request.get("video_url")
        transcript_url = request.get("transcript_url")

    # Validate required parameters
    if not video_url:
        print("‚ùå ERROR: Missing video URL")
        return {"error": "Missing video URL. Provide either 'video_url' or 'amazon_data' with video assets."}

    print(f"‚úÖ Video URL: {video_url}")
    print(f"‚úÖ Transcript URL: {transcript_url}")

    try:
        result = extract_video_frames.remote(video_url, transcript_url, metadata)
        print("‚úÖ Processing completed successfully")
        return result
    except Exception as e:
        print(f"‚ùå Processing failed: {e}")
        import traceback
        traceback.print_exc()
        return {"error": f"Processing failed: {str(e)}"}


@app.function()
@modal.fastapi_endpoint(method="POST")
def test_hls_url(request: dict) -> dict:
    """
    Test endpoint to debug HLS URL accessibility.

    Payload: {"hls_url": "https://example.com/playlist.m3u8"}
    """
    import requests
    import m3u8
    import urllib.parse

    hls_url = request.get("hls_url")
    if not hls_url:
        return {"error": "Missing hls_url parameter"}

    try:
        # Test playlist accessibility
        response = requests.get(hls_url, timeout=10)
        response.raise_for_status()

        # Try to parse as M3U8
        playlist = m3u8.loads(response.text)

        result = {
            "playlist_accessible": True,
            "playlist_size": len(response.text),
            "is_variant_playlist": len(playlist.playlists) > 0,
            "segment_count": len(playlist.segments) if playlist.segments else 0,
            "variant_count": len(playlist.playlists) if playlist.playlists else 0
        }

        # Handle variant playlists (master playlists)
        if playlist.playlists:
            result["variant_details"] = []
            for i, variant in enumerate(playlist.playlists[:3]):  # Show first 3 variants
                variant_info = {
                    "bandwidth": variant.stream_info.bandwidth if variant.stream_info else None,
                    "resolution": f"{variant.stream_info.resolution[0]}x{variant.stream_info.resolution[1]}" if variant.stream_info and variant.stream_info.resolution else None,
                    "url": urllib.parse.urljoin(hls_url, variant.uri)
                }
                result["variant_details"].append(variant_info)

            # Test the first variant's media playlist
            if playlist.playlists:
                first_variant_url = urllib.parse.urljoin(hls_url, playlist.playlists[0].uri)
                result["first_variant_url"] = first_variant_url

                try:
                    variant_response = requests.get(first_variant_url, timeout=10)
                    variant_response.raise_for_status()

                    variant_playlist = m3u8.loads(variant_response.text)
                    result["variant_playlist_accessible"] = True
                    result["variant_segment_count"] = len(variant_playlist.segments)

                    # Test first segment from variant
                    if variant_playlist.segments:
                        base_url = urllib.parse.urljoin(first_variant_url, '.')
                        first_segment_url = urllib.parse.urljoin(base_url, variant_playlist.segments[0].uri)
                        result["first_segment_url"] = first_segment_url

                        try:
                            segment_response = requests.head(first_segment_url, timeout=5)
                            result["first_segment_accessible"] = segment_response.status_code == 200
                        except Exception as seg_e:
                            result["first_segment_error"] = str(seg_e)

                except Exception as var_e:
                    result["variant_playlist_error"] = str(var_e)

        # Test first segment if available (for media playlists)
        elif playlist.segments:
            base_url = urllib.parse.urljoin(hls_url, '.')
            first_segment_url = urllib.parse.urljoin(base_url, playlist.segments[0].uri)

            try:
                segment_response = requests.head(first_segment_url, timeout=5)
                result["first_segment_accessible"] = segment_response.status_code == 200
                result["first_segment_url"] = first_segment_url
            except Exception as seg_e:
                result["first_segment_error"] = str(seg_e)
                result["first_segment_url"] = first_segment_url

        return result

    except Exception as e:
        return {
            "error": str(e),
            "playlist_accessible": False,
            "hls_url": hls_url
        }


@app.local_entrypoint()
def main(video_url: str, transcript_url: str = None):
    """Local testing entrypoint"""
    import json
    result = extract_video_frames.remote(video_url, transcript_url)
    print(json.dumps(result, indent=2))
